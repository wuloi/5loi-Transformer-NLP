{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac9f5e0",
   "metadata": {},
   "source": [
    "<center><a href=\"https://5loi.com/about_loi\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81ba90",
   "metadata": {},
   "source": [
    "# 文本分类\n",
    "> Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e39c7",
   "metadata": {},
   "source": [
    "## 情感分析 ##\n",
    "> Sentimental Analysis\n",
    "\n",
    "在本笔记本中，您将学习如何微调一个预训练模型。具体来说，我们将使用一个用于情感分析的模型。\n",
    "\n",
    "**情感分析**是检测文本中情感的任务。我们将此问题建模为文本分类问题的一种简单形式。例如，“Gollum 的表演令人难以置信！”具有积极的情感，而“它既不浪漫也不像它应该的那样惊险。”具有消极的情感。在这种分析中，我们需要查看句子，并且我们只有两个类别：“正面”和“负面”。训练集中每个句子必须被标记为其中一个。情感分析被企业广泛用于识别客户在在线对话和反馈中对产品、品牌或服务的情感。\n",
    "\n",
    "\n",
    "**目录**<br>\n",
    "本笔记本涵盖以下部分：\n",
    "* 数据集\n",
    "    * 下载和预处理数据\n",
    "    * 数据标记（可选）\n",
    "* 使用预训练模型\n",
    "    * 下载模型\n",
    "    * 进行预测\n",
    "* 微调预训练模型 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef24a1c",
   "metadata": {},
   "source": [
    "## 数据集 ##\n",
    "> Dataset\n",
    "\n",
    "在本笔记本中，我们将使用[斯坦福情感树库 (Stanford Sentiment Treebank, SST-2)](https://nlp.stanford.edu/sentiment/index.html)语料库进行情感分析。数据包含一系列句子，并带有正面和负面的二元标签。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608f11c",
   "metadata": {},
   "source": [
    "对于文本分类，NeMo 要求数据采用特定的格式。数据需要以制表符分隔的文件（.tsv）格式存储，包含句子和标签两列。数据文件的每一行包含文本序列，其中单词之间用空格分隔，标签用[制表符]([TAB])分隔，即：`[单词] [空格] [单词] [空格] [单词] [制表符] [标签]`(`[WORD] [SPACE] [WORD] [SPACE] [WORD] [TAB] [LABEL]`)\n",
    "\n",
    "例如：\n",
    "* \n",
    "```\n",
    "hide new secretions from the parental units[TAB]0\n",
    "that loves its characters and communicates something rather beautiful about human nature[TAB]1\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b2c1e",
   "metadata": {},
   "source": [
    "### 下载和预处理数据 ###\n",
    "> Download and Preprocess Data\n",
    "\n",
    "我们已经为您准备好了 SST-2 数据集。它应该包含三个文件：train.tsv、dev.tsv 和 test.tsv，分别用于 `训练`(`training`)、`验证`(`validation`) 和 `测试`(`test`)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d29a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "# set data path\n",
    "DATA_DIR='data'\n",
    "DATA_DIR=os.path.join(DATA_DIR, 'SST-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea70c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check that data folder should contain train.tsv, dev.tsv, test.tsv\n",
    "!ls -l {DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07210d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preview data \n",
    "print('Train:')\n",
    "!head -n 5 {DATA_DIR}/train.tsv\n",
    "\n",
    "print('Dev:')\n",
    "!head -n 5 {DATA_DIR}/dev.tsv\n",
    "\n",
    "print('Test:')\n",
    "!head -n 5 {DATA_DIR}/test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95d292",
   "metadata": {},
   "source": [
    "`train.tsv` 和 `dev.tsv` 的格式与 NeMo 的格式非常接近，只是在文件开头多了一行标题。我们将删除这些多余的行。但是 `test.tsv` 的格式不同，并且此部分数据缺少标签。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 1d {DATA_DIR}/train.tsv > {DATA_DIR}/train_nemo_format.tsv\n",
    "!sed 1d {DATA_DIR}/dev.tsv > {DATA_DIR}/dev_nemo_format.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e69a2",
   "metadata": {},
   "source": [
    "## 微调预训练模型 ##\n",
    "> Fine-Tune a Pre-Trained Model\n",
    "\n",
    "文本分类模型通常由一个预训练的[BERT](https://arxiv.org/pdf/1810.04805.pdf)模型和一个文本分类层组成。为了进行训练，我们可以使用配置文件来定义模型。配置文件(config)包含几个重要的部分，包括：\n",
    "\n",
    "* **model**: 所有与模型相关的参数 - 语言模型(language model)、标记分类器(token classifier)、优化器(optimizer)和调度器(schedulers)、数据集(datasets)以及任何其他相关信息\n",
    "* **trainer**: 传递给 PyTorch Lightning 的任何参数\n",
    "\n",
    "_注意:_ NeMo 提供了一个创建配置文件的模板，建议将其作为起点，但只要遵循所需格式，您也可以创建自己的配置文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780d1645",
   "metadata": {},
   "source": [
    "### 配置文件 ###\n",
    "> Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define config path\n",
    "MODEL_CONFIG=\"text_classification_config.yaml\"\n",
    "WORK_DIR='WORK_DIR'\n",
    "os.makedirs(WORK_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05975ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model's configuration file \n",
    "BRANCH='main'\n",
    "config_dir = WORK_DIR + '/configs/'\n",
    "os.makedirs(config_dir, exist_ok=True)\n",
    "if not os.path.exists(config_dir + MODEL_CONFIG):\n",
    "    print('Downloading config file...')\n",
    "    wget.download(f'https://raw.githubusercontent.com/NVIDIA/NeMo/{BRANCH}/examples/nlp/text_classification/conf/' + MODEL_CONFIG, config_dir)\n",
    "else:\n",
    "    print ('config file already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db62d648",
   "metadata": {},
   "source": [
    "文本分类的配置文件 `text_classification_config.yaml` 指定了模型、训练和实验管理细节，例如文件位置、预训练模型和超参数。我们下载的 YAML 配置文件为大多数参数提供了默认值，但此实验必须指定一些项目。\n",
    "\n",
    "使用 `omegaconf` 包可以更轻松地查看每个 YAML 部分，它允许您使用“点”表示法访问和操作配置键。我们将使用 `OmegaConf` 工具查看每个部分的详细信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7375e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "CONFIG_DIR = \"/dli/task/WORK_DIR/configs\"\n",
    "CONFIG_FILE = \"text_classification_config.yaml\"\n",
    "\n",
    "config=OmegaConf.load(CONFIG_DIR + \"/\" + CONFIG_FILE)\n",
    "\n",
    "# print the entire configuration file\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03275286",
   "metadata": {},
   "source": [
    "请注意，某些配置文件行，包括 `model.dataset.data_dir`，在路径位置使用 `???`，这意味着用户需要指定这些字段的值。有关模型参数的详细信息，请参阅[文档](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/text_classification.html#training-the-text-classification-model)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3efb9",
   "metadata": {},
   "source": [
    "首先，我们需要在配置文件中设置 `num_classes`，它指定了数据集中类的数量。对于 SST-2，我们只有两个类（0-正面和 1-负面）。所以我们将 `num_classes` 设置为 2。模型也支持超过 2 个类。(0-positive, 1-negative)\n",
    "\n",
    "我们需要在配置文件中指定并设置 `model.train_ds.file_name`、`model.validation_ds.file_name` 和 `model.test_ds.file_name`，分别指向训练、验证和测试文件（如果存在）的路径。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee5325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls $DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd76f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set num_classes to 2\n",
    "config.model.dataset.num_classes=2\n",
    "\n",
    "# set file paths\n",
    "config.model.train_ds.file_path = os.path.join(DATA_DIR, 'train_nemo_format.tsv')\n",
    "config.model.validation_ds.file_path = os.path.join(DATA_DIR, 'dev_nemo_format.tsv')\n",
    "\n",
    "# You may change other params like batch size or the number of samples to be considered (-1 means all the samples)\n",
    "\n",
    "# print the model section\n",
    "print(OmegaConf.to_yaml(config.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(config.trainer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets modify some trainer configs\n",
    "\n",
    "# setup max number of steps to reduce training time for demonstration purposes of this tutorial\n",
    "# Training stops when max_step or max_epochs is reached (earliest)\n",
    "config.trainer.max_epochs = 1\n",
    "\n",
    "# print the trainer section\n",
    "print(OmegaConf.to_yaml(config.trainer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97be14f",
   "metadata": {},
   "source": [
    "注意：`OmegaConf.to_yaml()` 用于创建用于打印配置的正确格式。一旦 `text_classification_config.yaml` 文件加载到内存中，更改配置文件将需要重新定义 `config` 变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e547b",
   "metadata": {},
   "source": [
    "现在，我们准备初始化我们的模型。在模型初始化调用期间，将为训练和评估准备数据集和数据加载器。此外，将下载预训练的 BERT 模型，这可能需要几分钟，具体取决于所选 BERT 模型的大小。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0f38d",
   "metadata": {},
   "source": [
    "### 下载预训练模型 ###\n",
    "> Download Pre-Trained Model\n",
    "\n",
    "在初始化模型之前，我们可能希望修改一些模型配置。例如，我们可能希望将预训练的 BERT 模型更改为另一个模型。默认模型是 `bert-base-uncased`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724011a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nemo.collections import nlp as nemo_nlp\n",
    "\n",
    "# complete list of supported BERT-like models\n",
    "for model in nemo_nlp.modules.get_pretrained_lm_models_list(): \n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the BERT-like model, you want to use\n",
    "# set the `model.language_modelpretrained_model_name' parameter in the config to the model you want to use\n",
    "config.model.language_model.pretrained_model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da954cc",
   "metadata": {},
   "source": [
    "现在，我们准备初始化我们的模型。在模型初始化调用期间，数据集和数据加载器也将为训练和验证做好准备。\n",
    "\n",
    "此外，预训练的 BERT 模型将自动下载。请注意，第一次创建模型时，这可能需要几分钟，具体取决于所选 BERT 模型的大小。如果您的数据集很大，读取和处理所有数据集也可能需要一些时间。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06d707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nemo.collections.nlp.models import TextClassificationModel\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer=pl.Trainer(**config.trainer)\n",
    "text_classification_model=TextClassificationModel(cfg=config.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ad93a7",
   "metadata": {},
   "source": [
    "### 模型训练 ###\n",
    "> Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52be0f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start model training\n",
    "trainer.fit(text_classification_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97c14e",
   "metadata": {},
   "source": [
    "### 评估预测 ###\n",
    "> Evaluate Predictions\n",
    "\n",
    "对于推理，我们可以使用 `trainer.test()` 或 `model.classifytext()`。更多信息请参考[文档](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/nlp/models/text_classification/text_classification_model.py)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde1c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_config = OmegaConf.create({'file_path': config.model.validation_ds.file_path, 'batch_size': 64, 'shuffle': False, 'num_samples': -1})\n",
    "text_classification_model.setup_test_data(test_data_config=eval_config)\n",
    "trainer.test(model=text_classification_model, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48890987",
   "metadata": {},
   "source": [
    "### 推理 ###\n",
    "> Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26337d9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the list of queries for inference\n",
    "queries = ['by the end of no such thing the audience , like beatrice , has a watchful affection for the monster .', \n",
    "           'director rob marshall went out gunning to make a great one .', \n",
    "           'uneasy mishmash of styles and genres .']\n",
    "           \n",
    "# max_seq_length=512 is the maximum length BERT supports.       \n",
    "results = text_classification_model.classifytext(queries=queries, batch_size=3, max_seq_length=512)\n",
    "\n",
    "print('The prediction results of some sample queries with the trained model:')\n",
    "for query, result in zip(queries, results):\n",
    "    print(f'Query : {query}')\n",
    "    print(f'Predicted label: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8754d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart the kernel\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aa666",
   "metadata": {},
   "source": [
    "**干得好！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1d109",
   "metadata": {},
   "source": [
    "<center><a href=\"https://5loi.com/about_loi\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
